# Adding SMLs support for AgentQnA workflow in GenAIExamples on Intel Xeon platform

AgentQnA workflow in GenAIExamples uses LLM as an agent to intelligently decide the control flow in the pipeline. Currently, the workflow uses OpenAI paid API for LLM services on Xeon platform. The goal for this RFC to add support for open source SLMs locally deployed on Xeon through Ollama.
## Author(s)

Pratool Bharti

## Status

 `Under Review`

## Objective

List what problem will this solve? What are the goals and non-goals of this RFC?

## Motivation

List why this problem is valuable to solve? Whether some related work exists?

## Design Proposal

This is the heart of the document, used to elaborate the design philosophy and detail proposal.

## Alternatives Considered

List other alternatives if have, and corresponding pros/cons to each proposal.

## Compatibility

list possible incompatible interface or workflow changes if exists.

## Miscellaneous

List other information user and developer may care about, such as:

- Performance Impact, such as speed, memory, accuracy.
- Engineering Impact, such as binary size, startup time, build time, test times.
- Security Impact, such as code vulnerability.
- TODO List or staging plan.
